{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(0, 10, (10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "XXt = X.dot(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigVals, eigVecs = np.linalg.eig(XXt)\n",
    "eigValsIndices = eigVals.argsort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 7, 6, 8, 9, 5, 4, 2, 1, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigValsIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigValsIndices = eigValsIndices[:-3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.54173420e+02 +0.00000000e+00j,\n",
       "         1.01332945e+02 +0.00000000e+00j,\n",
       "         6.64936354e+01 +0.00000000e+00j,\n",
       "        -4.33857741e-14 +0.00000000e+00j,\n",
       "         1.23812381e-14 +4.69926005e-15j,\n",
       "         1.23812381e-14 -4.69926005e-15j,\n",
       "        -4.01756745e-15 +8.67758846e-15j,\n",
       "        -4.01756745e-15 -8.67758846e-15j,\n",
       "        -2.69588189e-15 +0.00000000e+00j,   2.02267113e-15 +0.00000000e+00j])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = eigVecs[:, eigValsIndices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18723896+0.j,  0.25285278+0.j],\n",
       "       [-0.50011632+0.j,  0.27028291+0.j],\n",
       "       [ 0.06263949+0.j,  0.41450369+0.j],\n",
       "       [-0.53057684+0.j,  0.25119143+0.j],\n",
       "       [-0.07438622+0.j,  0.27964501+0.j],\n",
       "       [ 0.24330675+0.j,  0.39014237+0.j],\n",
       "       [ 0.05569041+0.j,  0.37470013+0.j],\n",
       "       [-0.14710959+0.j,  0.30076512+0.j],\n",
       "       [ 0.57793946+0.j,  0.20271356+0.j],\n",
       "       [ 0.07682183+0.j,  0.35459434+0.j]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.mat(np.diag(np.sqrt(eigVals[eigValsIndices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtX = X.T.dot(X)\n",
    "eigVals, eigVecs = np.linalg.eig(XtX)\n",
    "eigValsIndices = eigVals.argsort()\n",
    "eigValsIndices = eigValsIndices[:-3:-1]\n",
    "V = eigVecs[:, eigValsIndices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.55797225,  0.30662856],\n",
       "       [ 0.63498108, -0.75602257],\n",
       "       [ 0.53429018,  0.57828089]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5+3j)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+3j - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 4, 0, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0, 4, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:-3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the NG20 dataset using the class sklearn LDA using 10 topics\n",
    "from __future__ import  print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sampes = 2000\n",
    "n_features = 1000\n",
    "n_topics = 20\n",
    "n_top_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print('Topic #%d' % topic_idx)\n",
    "        print(' '.join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset\n",
      "done in 1.254s\n"
     ]
    }
   ],
   "source": [
    "print('load dataset')\n",
    "t0 = time()\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "data_samples = dataset.data\n",
    "print('done in %0.3fs' % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tf features for LDA\n",
      "done in 1.550s\n"
     ]
    }
   ],
   "source": [
    "# use tf (raw term count) features for LDA\n",
    "print('extracting tf features for LDA')\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=n_features, stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "print('done in %0.3fs' % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tf-idf features for NMF\n",
      "done in 1.821s\n"
     ]
    }
   ],
   "source": [
    "# use tfidf feature for NMF\n",
    "print('extracting tf-idf features for NMF')\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, #max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "print('done in %0.3fs' % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting LDA models with tf features, n_sampes=2000 and n_features=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/master/ij10268/miniconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 13.892s\n"
     ]
    }
   ],
   "source": [
    "print('fitting LDA models with tf features, n_sampes=%d and n_features=%d' % (n_sampes, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5, learning_method='online', learning_offset=50., random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print('done in %0.3fs' % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting NMF models with tfidf features, n_sampes=2000 and n_features=1000\n",
      "done in 7.846s\n"
     ]
    }
   ],
   "source": [
    "print('fitting NMF models with tfidf features, n_sampes=%d and n_features=%d' % (n_sampes, n_features))\n",
    "nmf = NMF(n_components=n_topics, random_state=1, alpha=0.1, l1_ratio=.5)\n",
    "t0 = time()\n",
    "nmf.fit(tfidf)\n",
    "print('done in %0.3fs' % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topics in LDA model:\n",
      "Topic #0\n",
      "people gun state control right guns crime states law police\n",
      "Topic #1\n",
      "time question book years did like don space answer just\n",
      "Topic #2\n",
      "mr line rules science stephanopoulos title current define int yes\n",
      "Topic #3\n",
      "key chip keys clipper encryption number des algorithm use bit\n",
      "Topic #4\n",
      "edu com cs vs w7 cx mail uk 17 send\n",
      "Topic #5\n",
      "use does window problem way used point different case value\n",
      "Topic #6\n",
      "windows thanks know help db does dos problem like using\n",
      "Topic #7\n",
      "bike water effect road design media dod paper like turn\n",
      "Topic #8\n",
      "don just like think know people good ve going say\n",
      "Topic #9\n",
      "car new price good power used air sale offer ground\n",
      "Topic #10\n",
      "file available program edu ftp information files use image version\n",
      "Topic #11\n",
      "ax max b8f g9v a86 145 pl 1d9 0t 34u\n",
      "Topic #12\n",
      "government law privacy security legal encryption court fbi technology information\n",
      "Topic #13\n",
      "card bit memory output video color data mode monitor 16\n",
      "Topic #14\n",
      "drive scsi disk mac hard apple drives controller software port\n",
      "Topic #15\n",
      "god jesus people believe christian bible say does life church\n",
      "Topic #16\n",
      "year game team games season play hockey players league player\n",
      "Topic #17\n",
      "10 00 15 25 20 11 12 14 16 13\n",
      "Topic #18\n",
      "armenian israel armenians war people jews turkish israeli said women\n",
      "Topic #19\n",
      "president people new said health year university school day work\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('topics in LDA model:')\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topics in NMF model:\n",
      "Topic #0\n",
      "don people just think like time good know right ve\n",
      "Topic #1\n",
      "use program software edu available graphics pc ftp using server\n",
      "Topic #2\n",
      "god jesus bible christ faith believe christians christian heaven sin\n",
      "Topic #3\n",
      "geb dsl chastity n3jxp cadre shameful pitt intellect skepticism surrender\n",
      "Topic #4\n",
      "key chip encryption clipper keys escrow government algorithm security secure\n",
      "Topic #5\n",
      "drive disk drives hard floppy ide boot controller cd internal\n",
      "Topic #6\n",
      "mail address list send mailing post info edu com reply\n",
      "Topic #7\n",
      "thanks advance hi looking info appreciated help email anybody information\n",
      "Topic #8\n",
      "sale offer shipping price condition new asking sell best email\n",
      "Topic #9\n",
      "card video monitor vga bus drivers cards driver ati color\n",
      "Topic #10\n",
      "game team games players hockey year season play win league\n",
      "Topic #11\n",
      "windows dos ms microsoft os running nt version drivers driver\n",
      "Topic #12\n",
      "window manager application display motif xterm root position tvtwm expose\n",
      "Topic #13\n",
      "car cars dealer engine miles owner speed ford driving tires\n",
      "Topic #14\n",
      "does know anybody mean appreciated info exist help like doesn\n",
      "Topic #15\n",
      "israel israeli jews arab arabs lebanese lebanon peace israelis jewish\n",
      "Topic #16\n",
      "00 50 20 10 15 dos 30 25 cover 01\n",
      "Topic #17\n",
      "scsi ide controller bus isa bit pc mac devices dma\n",
      "Topic #18\n",
      "file files directory format bmp cview gif swap ftp exe\n",
      "Topic #19\n",
      "armenian armenians turkish genocide armenia turks turkey soviet muslim azerbaijan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('topics in NMF model:')\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   [ 0.          0.10522514  0.         ...,  0.          0.          0.        ]\n",
      "1   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "2   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "3   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "4   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "5   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "6   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "7   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "8   [ 0.00112823  0.07013121  0.         ...,  0.          0.          0.        ]\n",
      "9   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "10   [ 0.          0.01015273  0.         ...,  0.          0.          0.        ]\n",
      "11   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "12   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "13   [ 0.          0.03634624  0.         ...,  0.          0.          0.        ]\n",
      "14   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "15   [ 0.         0.0145849  0.        ...,  0.         0.         0.       ]\n",
      "16   [ 2.73515411  0.03825862  0.         ...,  0.          0.          0.        ]\n",
      "17   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "18   [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "19   [ 0.          0.09138045  0.         ...,  0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "for topicidx, topic in enumerate(nmf.components_):\n",
    "    print(topicidx, ' ', topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([[1, 1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=2, init='random', random_state=0)\n",
    "W = model.fit_transform(X)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.09783018,  0.30560234],\n",
       "       [ 2.13443044,  2.13171694]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.46880684],\n",
       "       [ 0.55699523,  0.3894146 ],\n",
       "       [ 1.00331638,  0.41925352],\n",
       "       [ 1.6733999 ,  0.22926926],\n",
       "       [ 2.34349311,  0.03927954],\n",
       "       [ 2.78981512,  0.06911798]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00063558,  0.99936347],\n",
       "       [ 1.99965977,  1.00034074],\n",
       "       [ 2.99965485,  1.20034566],\n",
       "       [ 3.9998681 ,  1.0001321 ],\n",
       "       [ 5.00009002,  0.79990984],\n",
       "       [ 6.00008587,  0.999914  ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.dot(H)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
