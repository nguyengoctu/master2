{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(0, 10, (10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "XXt = X.dot(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigVals, eigVecs = np.linalg.eig(XXt)\n",
    "eigValsIndices = eigVals.argsort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 7, 6, 8, 9, 5, 4, 2, 1, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigValsIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigValsIndices = eigValsIndices[:-3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.54173420e+02 +0.00000000e+00j,\n",
       "         1.01332945e+02 +0.00000000e+00j,\n",
       "         6.64936354e+01 +0.00000000e+00j,\n",
       "        -4.33857741e-14 +0.00000000e+00j,\n",
       "         1.23812381e-14 +4.69926005e-15j,\n",
       "         1.23812381e-14 -4.69926005e-15j,\n",
       "        -4.01756745e-15 +8.67758846e-15j,\n",
       "        -4.01756745e-15 -8.67758846e-15j,\n",
       "        -2.69588189e-15 +0.00000000e+00j,   2.02267113e-15 +0.00000000e+00j])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = eigVecs[:, eigValsIndices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18723896+0.j,  0.25285278+0.j],\n",
       "       [-0.50011632+0.j,  0.27028291+0.j],\n",
       "       [ 0.06263949+0.j,  0.41450369+0.j],\n",
       "       [-0.53057684+0.j,  0.25119143+0.j],\n",
       "       [-0.07438622+0.j,  0.27964501+0.j],\n",
       "       [ 0.24330675+0.j,  0.39014237+0.j],\n",
       "       [ 0.05569041+0.j,  0.37470013+0.j],\n",
       "       [-0.14710959+0.j,  0.30076512+0.j],\n",
       "       [ 0.57793946+0.j,  0.20271356+0.j],\n",
       "       [ 0.07682183+0.j,  0.35459434+0.j]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.mat(np.diag(np.sqrt(eigVals[eigValsIndices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtX = X.T.dot(X)\n",
    "eigVals, eigVecs = np.linalg.eig(XtX)\n",
    "eigValsIndices = eigVals.argsort()\n",
    "eigValsIndices = eigValsIndices[:-3:-1]\n",
    "V = eigVecs[:, eigValsIndices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.55797225,  0.30662856],\n",
       "       [ 0.63498108, -0.75602257],\n",
       "       [ 0.53429018,  0.57828089]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5+3j)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+3j - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 4, 0, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0, 4, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:-3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the NG20 dataset using the class sklearn LDA using 10 topics\n",
    "from __future__ import  print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.datasets import f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sampes = 2000\n",
    "n_features = 1000\n",
    "n_topics = 20\n",
    "n_top_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print('Topic #%d' % topic_idx)\n",
    "        print(' '.join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset\n",
      "done in 1.024s\n"
     ]
    }
   ],
   "source": [
    "print('load dataset')\n",
    "t0 = time()\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "data_samples = dataset.data\n",
    "print('done in %0.3fs' % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting tf features for LDA\n",
      "done in 1.320s\n"
     ]
    }
   ],
   "source": [
    "# use tf (raw term count) features for LDA\n",
    "print('extracting tf features for LDA')\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=n_features, stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "print('done in %0.3fs' % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting LDA models with tf features, n_sampes=2000 and n_features=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/master/ij10268/miniconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 13.892s\n"
     ]
    }
   ],
   "source": [
    "print('fitting LDA models with tf features, n_sampes=%d and n_features=%d' % (n_sampes, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5, learning_method='online', learning_offset=50., random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print('done in %0.3fs' % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topics in LDA model:\n",
      "Topic #0\n",
      "people gun state control right guns crime states law police\n",
      "Topic #1\n",
      "time question book years did like don space answer just\n",
      "Topic #2\n",
      "mr line rules science stephanopoulos title current define int yes\n",
      "Topic #3\n",
      "key chip keys clipper encryption number des algorithm use bit\n",
      "Topic #4\n",
      "edu com cs vs w7 cx mail uk 17 send\n",
      "Topic #5\n",
      "use does window problem way used point different case value\n",
      "Topic #6\n",
      "windows thanks know help db does dos problem like using\n",
      "Topic #7\n",
      "bike water effect road design media dod paper like turn\n",
      "Topic #8\n",
      "don just like think know people good ve going say\n",
      "Topic #9\n",
      "car new price good power used air sale offer ground\n",
      "Topic #10\n",
      "file available program edu ftp information files use image version\n",
      "Topic #11\n",
      "ax max b8f g9v a86 145 pl 1d9 0t 34u\n",
      "Topic #12\n",
      "government law privacy security legal encryption court fbi technology information\n",
      "Topic #13\n",
      "card bit memory output video color data mode monitor 16\n",
      "Topic #14\n",
      "drive scsi disk mac hard apple drives controller software port\n",
      "Topic #15\n",
      "god jesus people believe christian bible say does life church\n",
      "Topic #16\n",
      "year game team games season play hockey players league player\n",
      "Topic #17\n",
      "10 00 15 25 20 11 12 14 16 13\n",
      "Topic #18\n",
      "armenian israel armenians war people jews turkish israeli said women\n",
      "Topic #19\n",
      "president people new said health year university school day work\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('topics in LDA model:')\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
