{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "corpus = [\"aaa bbb! ccc aaa eee aaa ggg.\", \"ggg fff eee.\", \"ddd aaa ggg aaa eee.\"]\n",
    "\n",
    "def split_into_words(d):\n",
    "    d = re.sub(r\"\\W+\", \" \", d)\n",
    "    return d.split()\n",
    "\n",
    "vocabulary = defaultdict()\n",
    "vocabulary.default_factory = lambda: len(vocabulary)\n",
    "\n",
    "def docs2num(corpus, voc):\n",
    "    for doc in corpus:\n",
    "        yield [vocabulary[word] for word in split_into_words(doc)]\n",
    "\n",
    "docs = list(docs2num(corpus,vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaa', 'bbb', 'ccc', 'aaa', 'eee', 'aaa', 'ggg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_into_words(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>>,\n",
       "            {'aaa': 0,\n",
       "             'bbb': 1,\n",
       "             'ccc': 2,\n",
       "             'ddd': 6,\n",
       "             'eee': 3,\n",
       "             'fff': 5,\n",
       "             'ggg': 4})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the doc-term matrix\n",
    "nbDocs = len(docs)\n",
    "nbWords = len(vocabulary)\n",
    "\n",
    "docTermMatrix = np.zeros((nbDocs, nbWords), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docTermMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, d in enumerate(docs):\n",
    "    for w_num in d:\n",
    "        docTermMatrix[idx, w_num] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1, 1, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 1, 0],\n",
       "       [2, 0, 0, 1, 1, 0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docTermMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 0, 3, 0, 4], [4, 5, 3], [6, 0, 4, 0, 3]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd1', 'e', 'f', 'g']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"\\W+\", \" \", \"a b c d1 e f g.\").split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before standardization\n",
      "distance between d1 and d2: 52.202\n",
      "distance between d1 and d3: 4.243\n",
      "\n",
      "after standardization\n",
      "distance between d1 and d2: 2.901\n",
      "distance between d1 and d3: 3.009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_1 = np.array([1, 2, 0, 0])\n",
    "doc_2 = np.array([50, 20, 0, 0])\n",
    "doc_3 = np.array([0, 0, 2, 3])\n",
    "\n",
    "print(\"before standardization\")\n",
    "print(\"distance between d1 and d2: {:.3f}\".format(np.linalg.norm(doc_1 - doc_2)))\n",
    "print(\"distance between d1 and d3: {:.3f}\".format(np.linalg.norm(doc_1 - doc_3)))\n",
    "print()\n",
    "\n",
    "m = np.vstack((doc_1, doc_2, doc_3))\n",
    "d = np.diag((1. / m.std(axis=0)))\n",
    "# standardize\n",
    "m = m.dot(d)\n",
    "\n",
    "print(\"after standardization\")\n",
    "print(\"distance between d1 and d2: {:.3f}\".format(np.linalg.norm(m[0] - m[1])))\n",
    "print(\"distance between d1 and d3: {:.3f}\".format(np.linalg.norm(m[0] - m[2])))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=False, sublinear_tf=False)\n",
    "normalize_weighted_D = normalize(docTermMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.83205029,  0.2773501 ,  0.2773501 ,  0.2773501 ,  0.2773501 ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.57735027,  0.57735027,\n",
       "         0.57735027,  0.        ],\n",
       "       [ 0.75592895,  0.        ,  0.        ,  0.37796447,  0.37796447,\n",
       "         0.        ,  0.37796447]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_weighted_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.78860962,  0.39251202,  0.39251202,  0.18703408,  0.18703408,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.39515588,  0.39515588,\n",
       "          0.829279  ,  0.        ],\n",
       "        [ 0.74318769,  0.        ,  0.        ,  0.26439208,  0.26439208,\n",
       "          0.        ,  0.55485647]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit_transform(docTermMatrix).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 1, 1, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 1, 0],\n",
       "       [2, 0, 0, 1, 1, 0, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docTermMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
